{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3145d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.2 (tags/v3.9.2:1a79785, Feb 19 2021, 13:44:55) [MSC v.1928 64 bit (AMD64)]\n",
      "numba version: 1.23.4\n",
      "flopy version: 3.3.4\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import random\n",
    "import math\n",
    "from numpy import random\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import flopy\n",
    "import pandas\n",
    "import sklearn\n",
    "from collections import Counter\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from matplotlib import ticker\n",
    "from pymoo.core.problem import ElementwiseProblem\n",
    "from pymoo.factory import get_sampling, get_crossover, get_mutation\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from pymoo.operators.crossover.sbx import SBX\n",
    "from pymoo.decomposition.asf import ASF\n",
    "from pymoo.operators.mutation.pm import PM\n",
    "from pymoo.operators.sampling.rnd import FloatRandomSampling\n",
    "from pymoo.operators.sampling.rnd import IntegerRandomSampling\n",
    "from pymoo.operators.repair.rounding import RoundingRepair\n",
    "from pymoo.termination import get_termination\n",
    "from pymoo.decomposition.asf import ASF\n",
    "from pymoo.optimize import minimize\n",
    "import matplotlib.patches as mpatches\n",
    "import time\n",
    "from matplotlib.pyplot import MultipleLocator\n",
    "from itertools import product\n",
    "font = FontProperties(fname=r\"c:\\windows\\fonts\\simhei.ttf\", size=14)\n",
    "fontlegend = FontProperties(fname=r\"c:\\windows\\fonts\\simhei.ttf\", size=14)\n",
    "print(sys.version)\n",
    "print('numba version: {}'.format(np.__version__))\n",
    "print('flopy version: {}'.format(flopy.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ca4b5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "timel=[]\n",
    "with open('D:\\\\工作需\\\\R程序计算\\\\R程序翻译\\\\timeC13.txt', 'r+') as obj: #time file path\n",
    "    for line in obj.readlines():\n",
    "        timel.append(line)\n",
    "    timel = [line.strip(\"\\n\") for line in timel]\n",
    "Tlist=np.array(timel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ea595f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "read mppth file and save IJK\n",
    "'''\n",
    "def save_mp_resnb(pth_file, out_csv, tar_colnames=None, add_ij_info=False, in_model=None):\n",
    "    if tar_colnames == None:\n",
    "        tar_colnames = [\"particleid\", \"x\", \"y\", \"z\",\"time\", \"k\"]\n",
    "    pthobj = flopy.utils.PathlineFile(pth_file)\n",
    "    df_all = pandas.DataFrame(pthobj._data)[tar_colnames]\n",
    "    if add_ij_info:\n",
    "        i,j = in_model.dis.get_rc_from_node_coordinates(df_all[\"x\"].values, df_all[\"y\"].values)\n",
    "        df_all.insert(len(df_all.columns), \"i\", i)\n",
    "        df_all.insert(len(df_all.columns), \"j\", j)\n",
    "    df_all.to_csv(out_csv, index=None)\n",
    "    return \"Complete: %s\"%(pth_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b796a106",
   "metadata": {},
   "source": [
    "# CELL.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eaf32f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 | D:\\工作需\\R程序计算\\R程序翻译\\C13-test\\cell_1800.txt completed in 287.56s\n"
     ]
    }
   ],
   "source": [
    "workspace = os.path.join('.')\n",
    "def mpthcell(allname, modelname, welnum, hk):\n",
    "    nm=modelname\n",
    "    is_silent = True\n",
    "    in_mfn='D:/工作需/G-case/%s_MODFLOW_text/%s.mfn'%(allname,allname) #C13-test_MODFLOW_text path\n",
    "    m = flopy.modflow.Modflow.load(in_mfn, model_ws=workspace, version=\"mf2005\", exe_name = 'mf2005.exe')\n",
    "    nrow, ncol, nlay, nper = m.nrow_ncol_nlay_nper\n",
    "    m.write_input()\n",
    "    m.run_model(silent=is_silent)\n",
    "    \n",
    "    #particle in each cell\n",
    "    plocs = []\n",
    "    pids = []\n",
    "    ids=0\n",
    "    for kdx, idx, jdx in product(range(nlay),range(nrow),range(ncol)):\n",
    "        plocs.append((kdx, idx, jdx))\n",
    "        ids+=1\n",
    "        pids.append(ids)\n",
    "    part0 = flopy.modpath.ParticleData(\n",
    "        plocs, drape=0, structured=True, particleids=pids\n",
    "    )\n",
    "    pg0 = flopy.modpath.ParticleGroup(\n",
    "        particlegroupname=\"PG1\", particledata=part0, filename=\"ex01a.pg1.sloc\"\n",
    "    )\n",
    "    particlegroups = [pg0]\n",
    "    import time\n",
    "    for idx,i in enumerate(Tlist):\n",
    "        s = time.time()\n",
    "        # create modpath files\n",
    "        exe_name = \"mp7\"\n",
    "        mp = flopy.modpath.Modpath7(\n",
    "            modelname=nm + \"_mp\", flowmodel=m, exe_name=exe_name, model_ws=workspace, budgetfilename=\"%s.ccf\"%allname\n",
    "        )\n",
    "        mpbas = flopy.modpath.Modpath7Bas(mp)\n",
    "        mpsim = flopy.modpath.Modpath7Sim(\n",
    "            mp,\n",
    "            simulationtype=\"pathline\",\n",
    "            trackingdirection=\"forward\",\n",
    "            weaksinkoption=\"pass_through\",\n",
    "            weaksourceoption=\"pass_through\",\n",
    "            budgetoutputoption=\"summary\",\n",
    "            referencetime=[0, 0, 0.0],\n",
    "            stoptimeoption=\"specified\",\n",
    "            stoptime=int(i)-1,\n",
    "            zonedataoption=\"off\",\n",
    "            particlegroups=particlegroups,\n",
    "        )\n",
    "\n",
    "        # write modpath datasets\n",
    "        mp.write_input()\n",
    "        # run modpath\n",
    "        mp.run_model(silent=True)\n",
    "        fpth_file = workspace+\"/\"+nm+\"_mp.mppth\"\n",
    "        out_csv = workspace+\"/modpath_midresult.csv\"\n",
    "        save_mp_resnb(fpth_file, out_csv, add_ij_info=True, in_model=m)\n",
    "\n",
    "        df=pandas.read_csv(out_csv)\n",
    "        c=df.values.tolist()\n",
    "        carr=np.array(c, dtype='object')\n",
    "        rows, columns = carr.shape\n",
    "        columns=['Particle_Index', 'X', 'Y', 'Z', 'Time', 'Cell_K', 'Cell_I', 'Cell_J']\n",
    "        for i,j in product(range(rows),range(5,8)): \n",
    "            carr[i,j]=int(carr[i,j]+1)\n",
    "            carr[i,0]=int(carr[i,0])\n",
    "        carr=np.insert(carr, 0, values=columns, axis=0) \n",
    "        '''save path'''\n",
    "        txtc=[]\n",
    "        for i in Tlist:\n",
    "            txtcell = os.path.join(r\"D:\\工作需\\R程序计算\\R程序翻译\\%s\"%nm, r\"cell_%s.txt\"%i) #path to save cell.txt\n",
    "            txtc.append(txtcell)\n",
    "        wstxt=r\"D:/工作需/R程序计算/R程序翻译/\"+nm\n",
    "        if not os.path.exists(wstxt):\n",
    "            os.makedirs(wstxt)\n",
    "        with open(txtc[idx], 'w') as f: #保存至指定文件\n",
    "            np.savetxt(f, carr, fmt=\"%s\", delimiter=\"    \")\n",
    "        e = time.time()\n",
    "        print(\"%s/%s | %s completed in %.2fs\"%(idx+1, len(Tlist), txtc[idx], e-s))\n",
    "mpthcell(allname='C13-test', modelname='C13-test', welnum=1, hk=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d116a8",
   "metadata": {},
   "source": [
    "# IN.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9adb0381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mpthin(ptcl,i,inname):\n",
    "    workspace = os.path.join('.')\n",
    "    #定义模型名称和存储文件名\n",
    "    nm='C13-test'\n",
    "    is_silent = True  \n",
    "    in_mfn=r'D:/工作需/G-case/C13-test_MODFLOW_text/C13-test.mfn'#C13-test_MODFLOW_text path\n",
    "    m = flopy.modflow.Modflow.load(in_mfn, model_ws=workspace, version=\"mf2005\", exe_name = 'mf2005.exe')\n",
    "    nrow, ncol, nlay, nper = m.nrow_ncol_nlay_nper\n",
    "    m.write_input()\n",
    "    m.run_model(silent=is_silent)\n",
    "    #Add particles to all injection wells\n",
    "    data = pandas.read_table(r\"D:\\工作需\\R程序计算\\R程序翻译\\井坐标文件\\注井坐标C13.txt\", sep=\"\\\\s+\").values.tolist()#well file path\n",
    "    In_wel=np.array(data)\n",
    "    inw=In_wel[i:i+2,:]\n",
    "    plocs = []\n",
    "    pids = []\n",
    "    for i in inw:\n",
    "        plocs.append((int(i[2])-1,int(i[0])-1,int(i[1])-1))\n",
    "    Plocs=np.concatenate([plocs, plocs], axis=1)\n",
    "    cd = flopy.modpath.CellDataType(drape=0,\n",
    "                                   columncelldivisions=ptcl[0],\n",
    "                                   rowcelldivisions=ptcl[1],\n",
    "                                   layercelldivisions=ptcl[2])\n",
    "    p = flopy.modpath.LRCParticleData([cd], [Plocs])\n",
    "\n",
    "    pg1 = flopy.modpath.ParticleGroupLRCTemplate(particlegroupname=\"PG2\",\n",
    "                                            particledata=p,\n",
    "                                            filename=\"ex01a.pg2.sloc\")\n",
    "    particlegroupin = [pg1] \n",
    "    for idx,i in enumerate(Tlist):\n",
    "        s = time.time()\n",
    "        # create modpath files\n",
    "        exe_name = \"mp7\"\n",
    "        mp = flopy.modpath.Modpath7(\n",
    "            modelname=nm + \"_mp\", flowmodel=m, exe_name=exe_name, model_ws=workspace, budgetfilename=\"C13-test.ccf\"\n",
    "        )\n",
    "        mpbas = flopy.modpath.Modpath7Bas(mp)\n",
    "        mpsim = flopy.modpath.Modpath7Sim(\n",
    "            mp,\n",
    "            simulationtype=\"pathline\",\n",
    "            trackingdirection=\"forward\",\n",
    "            weaksinkoption=\"pass_through\",\n",
    "            weaksourceoption=\"pass_through\",\n",
    "            budgetoutputoption=\"summary\",\n",
    "            referencetime=[0, 0, 0.0], \n",
    "            stoptimeoption=\"specified\",\n",
    "            stoptime=int(i)-1,\n",
    "            zonedataoption=\"off\",\n",
    "            particlegroups=particlegroupin,\n",
    "        )\n",
    "\n",
    "        # write modpath datasets\n",
    "        mp.write_input()\n",
    "        # run modpath\n",
    "        mp.run_model(silent=True)\n",
    "        fpth_file = workspace+\"/\"+nm+\"_mp.mppth\"\n",
    "        out_csv = workspace+\"/modpath_midresult.csv\"\n",
    "        save_mp_resnb(fpth_file, out_csv, add_ij_info=True, in_model=m)\n",
    "        df=pandas.read_csv(out_csv) \n",
    "        c=df.values.tolist()\n",
    "        carr=np.array(c, dtype='object')\n",
    "        rows, columns = carr.shape\n",
    "        columns=['Particle_Index', 'X', 'Y', 'Z', 'Time', 'Cell_K', 'Cell_I', 'Cell_J']\n",
    "        for i,j in product(range(rows),range(5,8)): \n",
    "            carr[i,j]=int(carr[i,j]+1)\n",
    "            carr[i,0]=int(carr[i,0])\n",
    "        carr=np.insert(carr, 0, values=columns, axis=0)\n",
    "        '''save path'''\n",
    "        txtc=[]\n",
    "        for i in Tlist:\n",
    "            txtcell = os.path.join(r\"D:\\工作需\\R程序计算\\R程序翻译\\%s\"%nm, inname)#path to save cell.txt\n",
    "            txtc.append(txtcell)\n",
    "        wstxt=r\"D:/工作需/R程序计算/R程序翻译/\"+nm\n",
    "        if not os.path.exists(wstxt):\n",
    "            os.makedirs(wstxt)\n",
    "        with open(txtc[idx], 'w') as f: #保存至指定文件\n",
    "            np.savetxt(f, carr, fmt=\"%s\", delimiter=\"    \")\n",
    "        e = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5448159",
   "metadata": {},
   "outputs": [],
   "source": [
    "#injection wells file path\n",
    "wel = pandas.read_table(r'D:\\工作需\\R程序计算\\R程序翻译\\井坐标文件\\注井坐标C13.txt', sep=\"\\\\s+\").values.tolist()\n",
    "welarr = np.array(wel)\n",
    "#ore range file path\n",
    "mine = pandas.read_table(r'D:\\工作需\\R程序计算\\R程序翻译\\0222矿层.txt', sep=\"\\\\s+\").values.tolist()\n",
    "arrm=np.array(mine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf526ef",
   "metadata": {},
   "source": [
    "# calculation of the characteristic volume of in-situ uranium leaching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7c3709f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path=r\"D:/工作需/R程序计算/R程序翻译\" \n",
    "dir_path2=r\"D:/工作需/R程序计算/R程序翻译/C13-test\" #cel.txt and in,txt path\n",
    "timezlh=dir_path+\"/timeC13.txt\" #time file\n",
    "\n",
    "zlc_dir=dir_path+\"/总流场\"\n",
    "dylc_dir=dir_path+\"/单元流场\"\n",
    "\n",
    "jzb_dir=dir_path+\"/井坐标文件\" \n",
    "\n",
    "jzb_file_lis=os.listdir(jzb_dir)\n",
    "if jzb_file_lis[0].startswith(\"抽井\"):\n",
    "    cj_path=jzb_dir+\"/\"+jzb_file_lis[0]\n",
    "    zj_path=jzb_dir+\"/\"+jzb_file_lis[1]\n",
    "else:\n",
    "    cj_path = jzb_dir + \"/\" + jzb_file_lis[1]\n",
    "    zj_path = jzb_dir + \"/\" + jzb_file_lis[0]\n",
    "    \n",
    "def intjudge(x):\n",
    "    if  isinstance(x, int)==True:\n",
    "        index=-1\n",
    "    else:\n",
    "        index=1\n",
    "    return index\n",
    "    \n",
    "def newly_build_dir():\n",
    "    \"\"\" Check whether the save path exists, create it if it does not exist\"\"\"\n",
    "    for i in (zlc_dir,dylc_dir):\n",
    "        if not os.path.exists(i):\n",
    "            os.mkdir(i)\n",
    "\n",
    "def get_file_list(inname):\n",
    "    \"\"\" Get a list of files to process\"\"\"\n",
    "    with open(timezlh,\"r\",encoding=\"utf-8\") as f:\n",
    "        l=f.read().strip().split(\"\\n\")\n",
    "    file_list=[(i,dir_path2+\"/\"+\"cell_\"+i+\".txt\",dir_path2+\"/\"+inname) for i in l]\n",
    "    return file_list\n",
    "\n",
    "def get_cj_ijk():\n",
    "    \"\"\" ijk of pumping wells\"\"\"\n",
    "    data=pandas.read_csv(cj_path,sep=\"\\\\s+\",usecols=[\"I\",\"J\",\"K\"]).values.tolist()\n",
    "    set_data=set([tuple(i) for i in data]) \n",
    "    return set_data\n",
    "\n",
    "def get_zj_ijk(file_path):\n",
    "    \"\"\" ijk of injection wells\"\"\"\n",
    "    dic={}\n",
    "    data = pandas.read_table(zj_path, sep=\"\\\\s+\").values.tolist()\n",
    "    for i in data:\n",
    "        dic.setdefault(i[-1],set()).add(tuple(i[:3]))\n",
    "    for i in dic:\n",
    "        dic[i]=tuple(dic[i])\n",
    "    dic1={}\n",
    "    data = pandas.read_table(file_path, sep=\"\\\\s+\", usecols=[\"Particle_Index\",\"Time\", \"Cell_K\", \"Cell_I\", \"Cell_J\"])\n",
    "    data=data[[\"Particle_Index\",\"Time\", \"Cell_I\", \"Cell_J\", \"Cell_K\"]]\n",
    "    data[\"ijk\"]=data.apply(lambda x:(x[\"Cell_I\"],x[\"Cell_J\"],x[\"Cell_K\"]),axis=1)\n",
    "    for k,v in dic.items():\n",
    "        dic1[k]=set()\n",
    "        all_index=[]\n",
    "        for i in v:\n",
    "            p=data[(data[\"ijk\"]==i) & (data[\"Time\"]==0)]\n",
    "            l=p[\"Particle_Index\"].values.tolist()\n",
    "            all_index+=l\n",
    "        data1=data[data[\"Particle_Index\"].isin(all_index)][[\"Cell_I\", \"Cell_J\", \"Cell_K\"]].values.tolist()\n",
    "        for i in data1:\n",
    "            dic1[k].add(tuple(i))\n",
    "    return dic1\n",
    "\n",
    "def get_set_A(file_path):\n",
    "    \"\"\" get setA\"\"\"\n",
    "    cj_ijk=get_cj_ijk()\n",
    "    data = pandas.read_table(file_path,sep=\"\\\\s+\", usecols=[\"Particle_Index\",\"Time\",\"Cell_K\",\"Cell_I\",\"Cell_J\"])\n",
    "    data[\"ijk\"] = data.apply(lambda x: (x[\"Cell_I\"], x[\"Cell_J\"], x[\"Cell_K\"]), axis=1)\n",
    "    data1=data[data[\"ijk\"].isin(cj_ijk)][\"Particle_Index\"].values.tolist()\n",
    "    d=tuple(set(data1))\n",
    "    data=data[(data[\"Time\"]==0) & (data[\"Particle_Index\"].isin(d))][[\"Cell_I\",\"Cell_J\",\"Cell_K\"]].values.tolist()\n",
    "    set_data = set([tuple(i) for i in data]) \n",
    "    set_A=set_data\n",
    "    return set_A\n",
    "\n",
    "def get_set_B(file_path):\n",
    "    \"\"\" get setB\"\"\"\n",
    "    data = pandas.read_table(file_path, sep=\"\\\\s+\", usecols=[\"Time\", \"Cell_K\", \"Cell_I\", \"Cell_J\"])\n",
    "    data = data[[\"Cell_I\", \"Cell_J\", \"Cell_K\"]].values.tolist()\n",
    "    set_data = set([tuple(i) for i in data]) \n",
    "    return set_data\n",
    "\n",
    "def save_csv(csv_path,s):\n",
    "    \"\"\"Save a collection of flow fields as a csv file \"\"\"\n",
    "    data=pandas.DataFrame(data=tuple(s),columns=[\"Cell_I\", \"Cell_J\", \"Cell_K\"])\n",
    "    data.to_csv(csv_path,index=False)\n",
    "\n",
    "def zlc_save(d,j,b,c,set_A,set_B):\n",
    "    \"\"\" Save flow field calculation results\"\"\"\n",
    "    d=zlc_dir+\"/\"+d\n",
    "    if not os.path.exists(d):\n",
    "        os.mkdir(d)\n",
    "    save_csv(d+\"/有效对流流场.csv\",j)\n",
    "    save_csv(d+\"/总对流流场.csv\",b)\n",
    "    save_csv(d+\"/无效对流流场.csv\",c)\n",
    "    save_csv(d+\"/set_A.csv\",set_A)\n",
    "    save_csv(d+\"/set_B.csv\",set_B)\n",
    "def cal_Lv(data_mine,carr):\n",
    "    Vsum=0\n",
    "    data_mine=data_mine.tolist()\n",
    "    set_mine=set([tuple(i) for i in data_mine])\n",
    "    Vsum_set=set_mine & carr\n",
    "    Vsum=len(Vsum_set)*62.109\n",
    "    return Vsum\n",
    "\n",
    "def calculation_dylc(zj_ijk,set_A,n):\n",
    "    \"\"\" Calculation unit flow field\"\"\"\n",
    "    save_dic=dylc_dir+\"/\"+n\n",
    "    if not os.path.exists(save_dic):\n",
    "        os.mkdir(save_dic)\n",
    "    for k,v in zj_ijk.items():\n",
    "        d=save_dic+\"/\"+k\n",
    "        if not os.path.exists(d):\n",
    "            os.mkdir(d)\n",
    "        set_jiao = set_A & v  # 交集\n",
    "        set_bing = set_A | v  # 并集\n",
    "        set_cha = (set_A - v) | (v-set_A)  # 差集\n",
    "        save_csv(d + \"/有效对流流场.csv\", set_jiao)\n",
    "        save_csv(d + \"/总对流流场.csv\", set_bing)\n",
    "        save_csv(d + \"/无效对流流场.csv\", set_cha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4963de50",
   "metadata": {},
   "source": [
    "# single objective optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f85df229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculation(ptcl,i, inname):\n",
    "    newly_build_dir()\n",
    "    mpthin(ptcl,i,inname)\n",
    "    for i in get_file_list(inname):\n",
    "        set_A=get_set_A(i[1])\n",
    "        set_B=get_set_B(i[2])\n",
    "        set_jiao=set_A & set_B \n",
    "        Vm=cal_Lv(arrm,set_jiao)\n",
    "        set_bing=set_A | set_B \n",
    "        set_cha=(set_A - set_B) | (set_B - set_A) \n",
    "        zlc_save(i[0],set_jiao,set_bing,set_cha,set_A,set_B)\n",
    "        volume=len(set_jiao)*62.109\n",
    "    return Vm\n",
    "timearr=[]\n",
    "for k in range(1,31):\n",
    "    s=time.time()\n",
    "    Vm_save=[]\n",
    "    for i in range(1,21):\n",
    "        ptcl=[10,10,i]#K direction\n",
    "        filename='in_1800_%d.txt'%k\n",
    "        v_tp=calculation(ptcl,2*k-2,filename)#Optimize the number of particles dropped into each injection well separately\n",
    "        Vm_save.append(v_tp)\n",
    "    e=time.time()\n",
    "    timearr.append(e-s)\n",
    "    with open(r'D:\\工作需\\R程序计算\\R程序翻译\\单目标递增\\单目标-仅K变-%d.txt'%k, 'w') as f:\n",
    "        np.savetxt(f, Vm_save, fmt=\"%s\", delimiter=\"    \")\n",
    "#save running time\n",
    "with open(r'D:\\工作需\\R程序计算\\R程序翻译\\单目标递增\\单目标-仅K变-时间.txt', 'w') as f:\n",
    "    np.savetxt(f, timearr, fmt=\"%s\", delimiter=\"    \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd1435d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''read and analyze'''\n",
    "result=[]\n",
    "for i in range(1,31):\n",
    "    D_path=r'D:\\工作需\\R程序计算\\R程序翻译\\单目标递增\\单目标-仅K变-%d.txt'%i\n",
    "    D = pandas.read_table(D_path, sep=\"\\\\s+\").values.tolist()\n",
    "    arrD=np.array(D)\n",
    "    for k in range(1,len(arrD)):\n",
    "        percentage_difference = abs(arrD[k] - arrD[k-1]) / arrD[k-1] * 100\n",
    "        if percentage_difference <= 3:\n",
    "            result.append((k+5, arrD[k]))\n",
    "            break\n",
    "        if k==len(arrD)-1 and percentage_difference > 3:\n",
    "            result.append((20,arrD[k]))\n",
    "'''Save the best value'''\n",
    "with open(r'D:\\工作需\\R程序计算\\R程序翻译\\单目标递增\\单目标-仅K变稳定值.txt', 'w') as f:\n",
    "    np.savetxt(f, result, fmt=\"%s\", delimiter=\"    \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
