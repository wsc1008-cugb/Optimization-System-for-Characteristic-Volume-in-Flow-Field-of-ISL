{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3145d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.2 (tags/v3.9.2:1a79785, Feb 19 2021, 13:44:55) [MSC v.1928 64 bit (AMD64)]\n",
      "numba version: 1.23.4\n",
      "flopy version: 3.3.4\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import random\n",
    "import math\n",
    "from numpy import random\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import flopy\n",
    "import pandas\n",
    "import sklearn\n",
    "from collections import Counter\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from matplotlib import ticker\n",
    "from pymoo.core.problem import ElementwiseProblem\n",
    "from pymoo.factory import get_sampling, get_crossover, get_mutation\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from pymoo.operators.crossover.sbx import SBX\n",
    "from pymoo.decomposition.asf import ASF\n",
    "from pymoo.operators.mutation.pm import PM\n",
    "from pymoo.operators.sampling.rnd import FloatRandomSampling\n",
    "from pymoo.operators.sampling.rnd import IntegerRandomSampling\n",
    "from pymoo.operators.repair.rounding import RoundingRepair\n",
    "from pymoo.termination import get_termination\n",
    "from pymoo.decomposition.asf import ASF\n",
    "from pymoo.optimize import minimize\n",
    "import matplotlib.patches as mpatches\n",
    "import time\n",
    "from matplotlib.pyplot import MultipleLocator\n",
    "from itertools import product\n",
    "font = FontProperties(fname=r\"c:\\windows\\fonts\\simhei.ttf\", size=14)\n",
    "fontlegend = FontProperties(fname=r\"c:\\windows\\fonts\\simhei.ttf\", size=14)\n",
    "print(sys.version)\n",
    "print('numba version: {}'.format(np.__version__))\n",
    "print('flopy version: {}'.format(flopy.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ca4b5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "time=[]\n",
    "with open(r'D:\\\\工作需\\\\R程序计算\\\\R程序翻译\\\\timeC13.txt', 'r+') as obj:\n",
    "    for line in obj.readlines():\n",
    "        time.append(line)\n",
    "    time = [line.strip(\"\\n\") for line in time]\n",
    "Tlist=np.array(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ea595f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "read mppth file and save IJK\n",
    "'''\n",
    "def save_mp_resnb(pth_file, out_csv, tar_colnames=None, add_ij_info=False, in_model=None):\n",
    "    if tar_colnames == None:\n",
    "        tar_colnames = [\"particleid\", \"x\", \"y\", \"z\",\"time\", \"k\"]\n",
    "    pthobj = flopy.utils.PathlineFile(pth_file)\n",
    "    df_all = pandas.DataFrame(pthobj._data)[tar_colnames]\n",
    "    if add_ij_info:\n",
    "        i,j = in_model.dis.get_rc_from_node_coordinates(df_all[\"x\"].values, df_all[\"y\"].values)\n",
    "        df_all.insert(len(df_all.columns), \"i\", i)\n",
    "        df_all.insert(len(df_all.columns), \"j\", j)\n",
    "    df_all.to_csv(out_csv, index=None)\n",
    "    return \"Complete: %s\"%(pth_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b796a106",
   "metadata": {},
   "source": [
    "# CELL.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaf32f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace = os.path.join('.')\n",
    "def mpthcell(allname, modelname, welnum, hk):\n",
    "    nm=modelname\n",
    "    is_silent = True\n",
    "    in_mfn='D:/工作需/G-case/%s_MODFLOW_text/%s.mfn'%(allname,allname) #C13-test_MODFLOW_text path\n",
    "    m = flopy.modflow.Modflow.load(in_mfn, model_ws=workspace, version=\"mf2005\", exe_name = 'mf2005.exe')\n",
    "    nrow, ncol, nlay, nper = m.nrow_ncol_nlay_nper\n",
    "    m.write_input()\n",
    "    m.run_model(silent=is_silent)\n",
    "    \n",
    "    #particle in each cell\n",
    "    plocs = []\n",
    "    pids = []\n",
    "    ids=0\n",
    "    for kdx, idx, jdx in product(range(nlay),range(nrow),range(ncol)):\n",
    "        plocs.append((kdx, idx, jdx))\n",
    "        ids+=1\n",
    "        pids.append(ids)\n",
    "    part0 = flopy.modpath.ParticleData(\n",
    "        plocs, drape=0, structured=True, particleids=pids\n",
    "    )\n",
    "    pg0 = flopy.modpath.ParticleGroup(\n",
    "        particlegroupname=\"PG1\", particledata=part0, filename=\"ex01a.pg1.sloc\"\n",
    "    )\n",
    "    particlegroups = [pg0]\n",
    "    import time\n",
    "    for idx,i in enumerate(Tlist):\n",
    "        s = time.time()\n",
    "        # create modpath files\n",
    "        exe_name = \"mp7\"\n",
    "        mp = flopy.modpath.Modpath7(\n",
    "            modelname=nm + \"_mp\", flowmodel=m, exe_name=exe_name, model_ws=workspace, budgetfilename=\"%s.ccf\"%allname\n",
    "        )\n",
    "        mpbas = flopy.modpath.Modpath7Bas(mp)\n",
    "        mpsim = flopy.modpath.Modpath7Sim(\n",
    "            mp,\n",
    "            simulationtype=\"pathline\",\n",
    "            trackingdirection=\"forward\",\n",
    "            weaksinkoption=\"pass_through\",\n",
    "            weaksourceoption=\"pass_through\",\n",
    "            budgetoutputoption=\"summary\",\n",
    "            referencetime=[0, 0, 0.0],\n",
    "            stoptimeoption=\"specified\",\n",
    "            stoptime=int(i)-1,\n",
    "            zonedataoption=\"off\",\n",
    "            particlegroups=particlegroups,\n",
    "        )\n",
    "\n",
    "        # write modpath datasets\n",
    "        mp.write_input()\n",
    "        # run modpath\n",
    "        mp.run_model(silent=True)\n",
    "        fpth_file = workspace+\"/\"+nm+\"_mp.mppth\"\n",
    "        out_csv = workspace+\"/modpath_midresult.csv\"\n",
    "        save_mp_resnb(fpth_file, out_csv, add_ij_info=True, in_model=m)\n",
    "\n",
    "        df=pandas.read_csv(out_csv)\n",
    "        c=df.values.tolist()\n",
    "        carr=np.array(c, dtype='object')\n",
    "        rows, columns = carr.shape\n",
    "        columns=['Particle_Index', 'X', 'Y', 'Z', 'Time', 'Cell_K', 'Cell_I', 'Cell_J']\n",
    "        for i,j in product(range(rows),range(5,8)): \n",
    "            carr[i,j]=int(carr[i,j]+1)\n",
    "            carr[i,0]=int(carr[i,0])\n",
    "        carr=np.insert(carr, 0, values=columns, axis=0) \n",
    "        '''save path'''\n",
    "        txtc=[]\n",
    "        for i in Tlist:\n",
    "            txtcell = os.path.join(r\"D:\\工作需\\R程序计算\\R程序翻译\\%s\"%nm, r\"cell_%s.txt\"%i) #path to save cell.txt\n",
    "            txtc.append(txtcell)\n",
    "        wstxt=r\"D:/工作需/R程序计算/R程序翻译/\"+nm\n",
    "        if not os.path.exists(wstxt):\n",
    "            os.makedirs(wstxt)\n",
    "        with open(txtc[idx], 'w') as f: #保存至指定文件\n",
    "            np.savetxt(f, carr, fmt=\"%s\", delimiter=\"    \")\n",
    "        e = time.time()\n",
    "        print(\"%s/%s | %s completed in %.2fs\"%(idx+1, len(Tlist), txtc[idx], e-s))\n",
    "mpthcell(allname='C13-test', modelname='C13-test', welnum=1, hk=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d116a8",
   "metadata": {},
   "source": [
    "# IN.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f8eea1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inname=\"in_1800.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9adb0381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mpthin(ptcl,i,inname):\n",
    "    workspace = os.path.join('.')\n",
    "    #定义模型名称和存储文件名\n",
    "    nm='C13-test'\n",
    "    is_silent = True  \n",
    "    in_mfn=r'D:/工作需/G-case/C13-test_MODFLOW_text/C13-test.mfn'#C13-test_MODFLOW_text path\n",
    "    m = flopy.modflow.Modflow.load(in_mfn, model_ws=workspace, version=\"mf2005\", exe_name = 'mf2005.exe')\n",
    "    nrow, ncol, nlay, nper = m.nrow_ncol_nlay_nper\n",
    "    m.write_input()\n",
    "    m.run_model(silent=is_silent)\n",
    "    #Add particles to all injection wells\n",
    "    data = pandas.read_table(r\"D:\\工作需\\R程序计算\\R程序翻译\\井坐标文件\\注井坐标C13.txt\", sep=\"\\\\s+\").values.tolist()#well file path\n",
    "    In_wel=np.array(data)\n",
    "    inw=In_wel[i:i+2,:]\n",
    "    plocs = []\n",
    "    pids = []\n",
    "    for i in inw:\n",
    "        plocs.append((int(i[2])-1,int(i[0])-1,int(i[1])-1))\n",
    "    Plocs=np.concatenate([plocs, plocs], axis=1)\n",
    "    cd = flopy.modpath.CellDataType(drape=0,\n",
    "                                   columncelldivisions=ptcl[0],\n",
    "                                   rowcelldivisions=ptcl[1],\n",
    "                                   layercelldivisions=ptcl[2])\n",
    "    p = flopy.modpath.LRCParticleData([cd], [Plocs])\n",
    "\n",
    "    pg1 = flopy.modpath.ParticleGroupLRCTemplate(particlegroupname=\"PG2\",\n",
    "                                            particledata=p,\n",
    "                                            filename=\"ex01a.pg2.sloc\")\n",
    "    particlegroupin = [pg1] \n",
    "    for idx,i in enumerate(Tlist):\n",
    "        s = time.time()\n",
    "        # create modpath files\n",
    "        exe_name = \"mp7\"\n",
    "        mp = flopy.modpath.Modpath7(\n",
    "            modelname=nm + \"_mp\", flowmodel=m, exe_name=exe_name, model_ws=workspace, budgetfilename=\"C13-test.ccf\"\n",
    "        )\n",
    "        mpbas = flopy.modpath.Modpath7Bas(mp)\n",
    "        mpsim = flopy.modpath.Modpath7Sim(\n",
    "            mp,\n",
    "            simulationtype=\"pathline\",\n",
    "            trackingdirection=\"forward\",\n",
    "            weaksinkoption=\"pass_through\",\n",
    "            weaksourceoption=\"pass_through\",\n",
    "            budgetoutputoption=\"summary\",\n",
    "            referencetime=[0, 0, 0.0], \n",
    "            stoptimeoption=\"specified\",\n",
    "            stoptime=int(i)-1,\n",
    "            zonedataoption=\"off\",\n",
    "            particlegroups=particlegroupin,\n",
    "        )\n",
    "\n",
    "        # write modpath datasets\n",
    "        mp.write_input()\n",
    "        # run modpath\n",
    "        mp.run_model(silent=True)\n",
    "        fpth_file = workspace+\"/\"+nm+\"_mp.mppth\"\n",
    "        out_csv = workspace+\"/modpath_midresult.csv\"\n",
    "        save_mp_resnb(fpth_file, out_csv, add_ij_info=True, in_model=m)\n",
    "        df=pandas.read_csv(out_csv) \n",
    "        c=df.values.tolist()\n",
    "        carr=np.array(c, dtype='object')\n",
    "        rows, columns = carr.shape\n",
    "        columns=['Particle_Index', 'X', 'Y', 'Z', 'Time', 'Cell_K', 'Cell_I', 'Cell_J']\n",
    "        for i,j in product(range(rows),range(5,8)): \n",
    "            carr[i,j]=int(carr[i,j]+1)\n",
    "            carr[i,0]=int(carr[i,0])\n",
    "        carr=np.insert(carr, 0, values=columns, axis=0)\n",
    "        '''save path'''\n",
    "        txtc=[]\n",
    "        for i in Tlist:\n",
    "            txtcell = os.path.join(r\"D:\\工作需\\R程序计算\\R程序翻译\\%s\"%nm, inname)#path to save cell.txt\n",
    "            txtc.append(txtcell)\n",
    "        wstxt=r\"D:/工作需/R程序计算/R程序翻译/\"+nm\n",
    "        if not os.path.exists(wstxt):\n",
    "            os.makedirs(wstxt)\n",
    "        with open(txtc[idx], 'w') as f: #保存至指定文件\n",
    "            np.savetxt(f, carr, fmt=\"%s\", delimiter=\"    \")\n",
    "        e = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5448159",
   "metadata": {},
   "outputs": [],
   "source": [
    "#injection wells file path\n",
    "wel = pandas.read_table(r'D:\\工作需\\R程序计算\\R程序翻译\\井坐标文件\\注井坐标C13.txt', sep=\"\\\\s+\").values.tolist()\n",
    "welarr = np.array(wel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf526ef",
   "metadata": {},
   "source": [
    "# calculation of the characteristic volume of in-situ uranium leaching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7c3709f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path=r\"D:/工作需/R程序计算/R程序翻译\" \n",
    "dir_path2=r\"D:/工作需/R程序计算/R程序翻译/C13-test\" #cel.txt and in,txt path\n",
    "timezlh=dir_path+\"/timeC13.txt\" #time file\n",
    "\n",
    "zlc_dir=dir_path+\"/总流场\"\n",
    "dylc_dir=dir_path+\"/单元流场\"\n",
    "\n",
    "jzb_dir=dir_path+\"/井坐标文件\" \n",
    "\n",
    "jzb_file_lis=os.listdir(jzb_dir)\n",
    "if jzb_file_lis[0].startswith(\"抽井\"):\n",
    "    cj_path=jzb_dir+\"/\"+jzb_file_lis[0]\n",
    "    zj_path=jzb_dir+\"/\"+jzb_file_lis[1]\n",
    "else:\n",
    "    cj_path = jzb_dir + \"/\" + jzb_file_lis[1]\n",
    "    zj_path = jzb_dir + \"/\" + jzb_file_lis[0]\n",
    "    \n",
    "def intjudge(x):\n",
    "    if  isinstance(x, int)==True:\n",
    "        index=-1\n",
    "    else:\n",
    "        index=1\n",
    "    return index\n",
    "    \n",
    "def newly_build_dir():\n",
    "    \"\"\" Check whether the save path exists, create it if it does not exist\"\"\"\n",
    "    for i in (zlc_dir,dylc_dir):\n",
    "        if not os.path.exists(i):\n",
    "            os.mkdir(i)\n",
    "\n",
    "def get_file_list(inname):\n",
    "    \"\"\" Get a list of files to process\"\"\"\n",
    "    with open(timezlh,\"r\",encoding=\"utf-8\") as f:\n",
    "        l=f.read().strip().split(\"\\n\")\n",
    "    file_list=[(i,dir_path2+\"/\"+\"cell_\"+i+\".txt\",dir_path2+\"/\"+inname) for i in l]\n",
    "    return file_list\n",
    "\n",
    "def get_cj_ijk():\n",
    "    \"\"\" ijk of pumping wells\"\"\"\n",
    "    data=pandas.read_csv(cj_path,sep=\"\\\\s+\",usecols=[\"I\",\"J\",\"K\"]).values.tolist()\n",
    "    set_data=set([tuple(i) for i in data]) \n",
    "    return set_data\n",
    "\n",
    "def get_zj_ijk(file_path):\n",
    "    \"\"\" ijk of injection wells\"\"\"\n",
    "    dic={}\n",
    "    data = pandas.read_table(zj_path, sep=\"\\\\s+\").values.tolist()\n",
    "    for i in data:\n",
    "        dic.setdefault(i[-1],set()).add(tuple(i[:3]))\n",
    "    for i in dic:\n",
    "        dic[i]=tuple(dic[i])\n",
    "    dic1={}\n",
    "    data = pandas.read_table(file_path, sep=\"\\\\s+\", usecols=[\"Particle_Index\",\"Time\", \"Cell_K\", \"Cell_I\", \"Cell_J\"])\n",
    "    data=data[[\"Particle_Index\",\"Time\", \"Cell_I\", \"Cell_J\", \"Cell_K\"]]\n",
    "    data[\"ijk\"]=data.apply(lambda x:(x[\"Cell_I\"],x[\"Cell_J\"],x[\"Cell_K\"]),axis=1)\n",
    "    for k,v in dic.items():\n",
    "        dic1[k]=set()\n",
    "        all_index=[]\n",
    "        for i in v:\n",
    "            p=data[(data[\"ijk\"]==i) & (data[\"Time\"]==0)]\n",
    "            l=p[\"Particle_Index\"].values.tolist()\n",
    "            all_index+=l\n",
    "        data1=data[data[\"Particle_Index\"].isin(all_index)][[\"Cell_I\", \"Cell_J\", \"Cell_K\"]].values.tolist()\n",
    "        for i in data1:\n",
    "            dic1[k].add(tuple(i))\n",
    "    return dic1\n",
    "\n",
    "def get_set_A(file_path):\n",
    "    \"\"\" get setA\"\"\"\n",
    "    cj_ijk=get_cj_ijk()\n",
    "    data = pandas.read_table(file_path,sep=\"\\\\s+\", usecols=[\"Particle_Index\",\"Time\",\"Cell_K\",\"Cell_I\",\"Cell_J\"])\n",
    "    data[\"ijk\"] = data.apply(lambda x: (x[\"Cell_I\"], x[\"Cell_J\"], x[\"Cell_K\"]), axis=1)\n",
    "    data1=data[data[\"ijk\"].isin(cj_ijk)][\"Particle_Index\"].values.tolist()\n",
    "    d=tuple(set(data1))\n",
    "    data=data[(data[\"Time\"]==0) & (data[\"Particle_Index\"].isin(d))][[\"Cell_I\",\"Cell_J\",\"Cell_K\"]].values.tolist()\n",
    "    set_data = set([tuple(i) for i in data]) \n",
    "    set_A=set_data\n",
    "    return set_A\n",
    "\n",
    "def get_set_B(file_path):\n",
    "    \"\"\" get setB\"\"\"\n",
    "    data = pandas.read_table(file_path, sep=\"\\\\s+\", usecols=[\"Time\", \"Cell_K\", \"Cell_I\", \"Cell_J\"])\n",
    "    data = data[[\"Cell_I\", \"Cell_J\", \"Cell_K\"]].values.tolist()\n",
    "    set_data = set([tuple(i) for i in data]) \n",
    "    return set_data\n",
    "\n",
    "def save_csv(csv_path,s):\n",
    "    \"\"\"Save a collection of flow fields as a csv file \"\"\"\n",
    "    data=pandas.DataFrame(data=tuple(s),columns=[\"Cell_I\", \"Cell_J\", \"Cell_K\"])\n",
    "    data.to_csv(csv_path,index=False)\n",
    "\n",
    "def zlc_save(d,j,b,c,set_A,set_B):\n",
    "    \"\"\" Save flow field calculation results\"\"\"\n",
    "    d=zlc_dir+\"/\"+d\n",
    "    if not os.path.exists(d):\n",
    "        os.mkdir(d)\n",
    "    save_csv(d+\"/有效对流流场.csv\",j)\n",
    "    save_csv(d+\"/总对流流场.csv\",b)\n",
    "    save_csv(d+\"/无效对流流场.csv\",c)\n",
    "    save_csv(d+\"/set_A.csv\",set_A)\n",
    "    save_csv(d+\"/set_B.csv\",set_B)\n",
    "def cal_Lv(data_mine,carr):\n",
    "    Vsum=0\n",
    "    data_mine=data_mine.tolist()\n",
    "    set_mine=set([tuple(i) for i in data_mine])\n",
    "    Vsum_set=set_mine & carr\n",
    "    Vsum=len(Vsum_set)*62.109\n",
    "    return Vsum\n",
    "\n",
    "def calculation_dylc(zj_ijk,set_A,n):\n",
    "    \"\"\" Calculation unit flow field\"\"\"\n",
    "    save_dic=dylc_dir+\"/\"+n\n",
    "    if not os.path.exists(save_dic):\n",
    "        os.mkdir(save_dic)\n",
    "    for k,v in zj_ijk.items():\n",
    "        d=save_dic+\"/\"+k\n",
    "        if not os.path.exists(d):\n",
    "            os.mkdir(d)\n",
    "        set_jiao = set_A & v  # 交集\n",
    "        set_bing = set_A | v  # 并集\n",
    "        set_cha = (set_A - v) | (v-set_A)  # 差集\n",
    "        save_csv(d + \"/有效对流流场.csv\", set_jiao)\n",
    "        save_csv(d + \"/总对流流场.csv\", set_bing)\n",
    "        save_csv(d + \"/无效对流流场.csv\", set_cha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4963de50",
   "metadata": {},
   "source": [
    "# Multi-objective optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "52ddc42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mine = pandas.read_table(r'D:\\工作需\\R程序计算\\R程序翻译\\0222矿层.txt', sep=\"\\\\s+\").values.tolist()\n",
    "arrm = np.array(mine)\n",
    "class MyProblem(ElementwiseProblem):\n",
    "    def __init__(self):\n",
    "        super().__init__(n_var=1,  # Quantity\n",
    "                         n_obj=2,  # Target\n",
    "                         n_ieq_constr=2,  # Restrictions\n",
    "                         xl=np.array([1.0]),  # 流量下限\n",
    "                         xu=np.array([5.0]),  # 流量上限\n",
    "                         )\n",
    "\n",
    "    def _evaluate(self, x, out, *args, **kwargs):\n",
    "        vol = self.calculation(x)\n",
    "\n",
    "        '''target value'''\n",
    "        f1 = x     # Maximize the amount of fluid pumped\n",
    "        f2 = -vol  # Minimize the external influence range of the flow field\n",
    "\n",
    "        '''estrictions， <= 0'''\n",
    "        g1 = x - 10\n",
    "        g2 = 1 - x\n",
    "\n",
    "        out[\"F\"] = [f1, f2]\n",
    "        out[\"G\"] = [g1, g2]\n",
    "\n",
    "    def calculation(self, q):\n",
    "        newly_build_dir()\n",
    "        mpthcell('C13-test', 'C13-test', [q, 2 * q, 4 * q, -4 * q])\n",
    "        mpthin([q, 2 * q, 4 * q, -4 * q])  # 先执行IN的流场模拟\n",
    "        print('The pumping volume this time is：%s' % q)\n",
    "        for i in get_file_list():\n",
    "            set_A = get_set_A(i[1])\n",
    "            set_B = get_set_B(i[2])\n",
    "            set_jiao = set_A & set_B\n",
    "            arr_real = np.array([i for i in set_jiao])\n",
    "            Vm = cal_Lv(arrm, set_jiao)\n",
    "            set_bing = set_A | set_B\n",
    "            set_cha = (set_A - set_B) | (set_B - set_A)\n",
    "            zlc_save(i[0], set_jiao, set_bing, set_cha, set_A, set_B)\n",
    "            volume = len(set_bing) * 62.109 #Calculate the total convection field volume\n",
    "        return volume\n",
    "problem = MyProblem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b2004c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = NSGA2(\n",
    "    pop_size=30,  #Population size (number of first generations)\n",
    "    n_offsprings=5, #The number of descendants in each subsequent generation\n",
    "    sampling=IntegerRandomSampling(),\n",
    "    crossover=SBX(prob=0.7, eta=15),\n",
    "    mutation=PM(prob=0.05, eta=20),\n",
    "    eliminate_duplicates = True\n",
    ")\n",
    "'''Define termination principles'''\n",
    "termination = get_termination(\"n_gen\", 60)"
   ]
  },
   "source": [
    "'''Execute multi-objective optimizer process'''\n",
    "res = minimize(problem,\n",
    "               algorithm,\n",
    "               termination,\n",
    "               seed=1,\n",
    "               save_history=True,\n",
    "               verbose=True)\n",
    "\n",
    "X = res.X\n",
    "F = res.F # target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe85c42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.        ]\n",
      " [4.99599727]\n",
      " [2.41242626]\n",
      " [2.75365408]\n",
      " [3.81326321]\n",
      " [4.85122022]\n",
      " [3.56508091]\n",
      " [4.12609265]\n",
      " [2.03282053]\n",
      " [1.8157449 ]\n",
      " [3.41019829]\n",
      " [4.49289212]\n",
      " [3.23677106]\n",
      " [1.21648957]\n",
      " [1.11733804]\n",
      " [1.65707645]\n",
      " [4.45869155]\n",
      " [4.02360486]\n",
      " [1.68503299]\n",
      " [3.10331328]\n",
      " [2.97287625]\n",
      " [2.26038519]\n",
      " [1.38921485]\n",
      " [2.34980939]\n",
      " [1.90813033]\n",
      " [2.83733402]\n",
      " [1.02938406]\n",
      " [1.30179909]\n",
      " [1.38600853]\n",
      " [2.14766346]]\n",
      "[[ 1.00000000e+00 -2.08003041e+05]\n",
      " [ 4.99599727e+00 -2.90608011e+05]\n",
      " [ 2.41242626e+00 -2.54025810e+05]\n",
      " [ 2.75365408e+00 -2.62099980e+05]\n",
      " [ 3.81326321e+00 -2.79179955e+05]\n",
      " [ 4.85122022e+00 -2.89303722e+05]\n",
      " [ 3.56508091e+00 -2.75329197e+05]\n",
      " [ 4.12609265e+00 -2.83217040e+05]\n",
      " [ 2.03282053e+00 -2.42721972e+05]\n",
      " [ 1.81574490e+00 -2.35765764e+05]\n",
      " [ 3.41019829e+00 -2.73341709e+05]\n",
      " [ 4.49289212e+00 -2.86198272e+05]\n",
      " [ 3.23677106e+00 -2.70236259e+05]\n",
      " [ 1.21648957e+00 -2.16636192e+05]\n",
      " [ 1.11733804e+00 -2.12474889e+05]\n",
      " [ 1.65707645e+00 -2.28747447e+05]\n",
      " [ 4.45869155e+00 -2.85701400e+05]\n",
      " [ 4.02360486e+00 -2.81602206e+05]\n",
      " [ 1.68503299e+00 -2.30362281e+05]\n",
      " [ 3.10331328e+00 -2.68000335e+05]\n",
      " [ 2.97287625e+00 -2.65578084e+05]\n",
      " [ 2.26038519e+00 -2.49553962e+05]\n",
      " [ 1.38921485e+00 -2.25393561e+05]\n",
      " [ 2.34980939e+00 -2.51603559e+05]\n",
      " [ 1.90813033e+00 -2.38933323e+05]\n",
      " [ 2.83733402e+00 -2.63590596e+05]\n",
      " [ 1.02938406e+00 -2.09121003e+05]\n",
      " [ 1.30179909e+00 -2.20549059e+05]\n",
      " [ 1.38600853e+00 -2.25269343e+05]\n",
      " [ 2.14766346e+00 -2.46262185e+05]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'一些注释需要注意的'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X)\n",
    "print(F)\n",
    "'''save'''\n",
    "with open(r'D:\\工作需\\R程序计算\\R程序翻译\\流量XF结果\\X-Q.txt', 'w') as f:\n",
    "    np.savetxt(f, X, fmt=\"%s\", delimiter=\"    \")\n",
    "with open(r'D:\\工作需\\R程序计算\\R程序翻译\\流量XF结果\\F-Q.txt', 'w') as f:\n",
    "    np.savetxt(f, F, fmt=\"%s\", delimiter=\"    \")\n",
    "'''read'''\n",
    "arrF=np.array(F)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "nF = MinMaxScaler().fit_transform(arrF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5c4b6e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5 0.5]\n"
     ]
    }
   ],
   "source": [
    "'''Entropy weight method determines the weight of two goals'''\n",
    "def Entropy(data):    \n",
    "    P_ij = data / data.sum(axis=0)\n",
    "    e_ij = (-1 / np.log(data.shape[0])) * P_ij * np.log(P_ij)\n",
    "    e_ij = np.where(np.isnan(e_ij), 0.0, e_ij)\n",
    "    return (1 - e_ij.sum(axis=0)) / (1 - e_ij.sum(axis=0)).sum()\n",
    "\n",
    "weights = np.array([0.5,0.5])\n",
    "print(weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
